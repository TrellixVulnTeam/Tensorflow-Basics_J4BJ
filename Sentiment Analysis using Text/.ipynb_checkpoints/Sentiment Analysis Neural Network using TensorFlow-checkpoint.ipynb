{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from Creating_Lexicon_and_Dealing_with_the_Text_Data_using_NLTK import create_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the function above to import the data in the format we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = create_labels('pos.txt','neg.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model, this can be anything\n",
    "nodes_hidden_layer_1 = 500\n",
    "nodes_hidden_layer_2 = 600\n",
    "nodes_hidden_layer_3 = 700\n",
    "nodes_hidden_layer_4 = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have 2 classes for the classification here, from 0 and 1 that is, positive and negative, therefore,\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to define the batch size, this means that it will do the whole computation in batches of 100,\n",
    "# Basically taking 100 features at a time.\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''We have to define place holders for the input and output to run whole thing in session, 784 is 28*28 to \n",
    "define the shape of the image''' \n",
    "X = tf.placeholder('float', [None, len(train_x[0])])\n",
    "Y = tf.placeholder('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Defining Neural Network\n",
    "Weights and Biases are tensorflow variable. Biases are added to Input times Variable, \n",
    "workflow is basically first hidden layer input will be the same as our input. \n",
    "However, from the second layer, the output of first will become input of second and so on\n",
    "and so forth. After last hidden layer, output we desire to have a class, so that is where num_classes \n",
    "comes into play\n",
    "'''\n",
    "\n",
    "def neural_net(Dataset_input):\n",
    "    \n",
    "    hidden_layer_1 = {'weights':tf.Variable(tf.random_normal([len(train_x[0]), nodes_hidden_layer_1]))\n",
    "                     , 'bias':tf.Variable(tf.random_normal([nodes_hidden_layer_1]))}\n",
    "    \n",
    "    hidden_layer_2 = {'weights':tf.Variable(tf.random_normal([nodes_hidden_layer_1, nodes_hidden_layer_2]))\n",
    "                     , 'bias':tf.Variable(tf.random_normal([nodes_hidden_layer_2]))}\n",
    "    \n",
    "    hidden_layer_3 = {'weights':tf.Variable(tf.random_normal([nodes_hidden_layer_2, nodes_hidden_layer_3]))\n",
    "                     , 'bias':tf.Variable(tf.random_normal([nodes_hidden_layer_3]))}\n",
    "    \n",
    "    hidden_layer_4 = {'weights':tf.Variable(tf.random_normal([nodes_hidden_layer_3, nodes_hidden_layer_4]))\n",
    "                     , 'bias':tf.Variable(tf.random_normal([nodes_hidden_layer_4]))}\n",
    "    \n",
    "    output_layer = {'weights':tf.Variable(tf.random_normal([nodes_hidden_layer_4, num_classes]))\n",
    "                     , 'bias':tf.Variable(tf.random_normal([num_classes]))}\n",
    "    \n",
    "    '''Defining Computation'''\n",
    "    \n",
    "    layer_1 = tf.add(tf.matmul(X,hidden_layer_1['weights']), hidden_layer_1['bias'])\n",
    "    #Applying activation function\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    layer_2 = tf.add(tf.matmul(layer_1,hidden_layer_2['weights']), hidden_layer_2['bias'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    layer_3 = tf.add(tf.matmul(layer_2,hidden_layer_3['weights']), hidden_layer_3['bias'])\n",
    "    layer_3 = tf.nn.relu(layer_3)\n",
    "    \n",
    "    layer_4 = tf.add(tf.matmul(layer_3,hidden_layer_4['weights']), hidden_layer_4['bias'])\n",
    "    layer_4 = tf.nn.relu(layer_4)\n",
    "    \n",
    "    output = tf.add(tf.matmul(layer_4,output_layer['weights']), output_layer['bias'])\n",
    "    #print('neural ok!')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining train Function\n",
    "\n",
    "def train(X):\n",
    "    \n",
    "    pred = neural_net(X)\n",
    "    \n",
    "    cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred,labels=Y))\n",
    "    '''Mininmizing cost function'''\n",
    "    # Using Gradient Descent\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost_function)\n",
    "    \n",
    "    \n",
    "    Num_Epochs = 6\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer()) # All it does is initialize the variables, weights and bias what we need to initialize\n",
    "        \n",
    "        for epoch in range(Num_Epochs):\n",
    "            loss = 0\n",
    "            \n",
    "            i = 0\n",
    "            while i<len(train_x):\n",
    "                start = i\n",
    "                end = i+batch_size\n",
    "                \n",
    "                batch_x = np.array(train_x[start:end])\n",
    "                batch_y = np.array(train_y[start:end])\n",
    "                n, c = sess.run([optimizer, cost_function], feed_dict ={X:batch_x,Y:batch_y})\n",
    "                loss +=c #adding cost \n",
    "                i+=batch_size\n",
    "            print('Epoch ', epoch, 'out of ', Num_Epochs, 'loss: ', loss)\n",
    "        summary = tf.summary.FileWriter('log/sentiment-analysis',sess.graph)\n",
    "        # tf.argmax ---> returns index of the maximum value, below line is just verifying that we are getting no more than 1 as output because it is one hot encoded\n",
    "        check = tf.equal(tf.argmax(pred,1), tf.argmax(Y,1))\n",
    "        # tf.cast just changes to the dtype\n",
    "        accuracy = tf.reduce_mean(tf.cast(check, tf.float32))\n",
    "        print('Accuracy: ', accuracy.eval({X:test_x, Y:test_y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 out of  6 loss:  1467957.61279\n",
      "Epoch  1 out of  6 loss:  574386.276855\n",
      "Epoch  2 out of  6 loss:  315260.037842\n",
      "Epoch  3 out of  6 loss:  178032.928894\n",
      "Epoch  4 out of  6 loss:  104436.282104\n",
      "Epoch  5 out of  6 loss:  70425.4329987\n",
      "Accuracy:  0.561914\n"
     ]
    }
   ],
   "source": [
    "train(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yayy! Model ran, I know accuracy is not pleasing but still we manage to make sentiment analysis model using TensorFlow. We can see the tensorboard as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tensorboard --logdir=log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is obviously just a snapshot of how tensorboard will look, there are 423 features, so you cannot get a glance at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![computational graph](Computational_Graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
